{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5f2187",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning - Heart Disease Dataset\n",
    "\n",
    "## Steps to Complete:\n",
    "1. Use GridSearchCV & RandomizedSearchCV to optimize model hyperparameters\n",
    "2. Compare optimized models with baseline performance\n",
    "\n",
    "## Deliverable:\n",
    "- Best performing model with optimized hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb670243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from scipy.stats import randint, uniform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a937675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Data ready for tuning!\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data (same as notebook 01)\n",
    "print(\"Loading and preparing data...\")\n",
    "\n",
    "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
    "                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "\n",
    "df = pd.read_csv('../data/Heart_Disease.csv', names=column_names, na_values='?')\n",
    "df_clean = df.dropna()\n",
    "\n",
    "categorical_columns = ['cp', 'restecg', 'slope', 'ca', 'thal']\n",
    "numerical_columns = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "# One-hot encoding\n",
    "df_encoded = pd.get_dummies(df_clean, columns=categorical_columns, prefix=categorical_columns)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df_encoded[numerical_columns] = scaler.fit_transform(df_encoded[numerical_columns])\n",
    "\n",
    "# Create target\n",
    "df_encoded['target_binary'] = (df_encoded['target'] > 0).astype(int)\n",
    "\n",
    "# Features / target\n",
    "feature_columns = [col for col in df_encoded.columns if col not in ['target', 'target_binary']]\n",
    "X = df_encoded[feature_columns]\n",
    "y = df_encoded['target_binary']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Data ready for tuning!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1d82760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline models...\n",
      "Baseline results (F1, AUC):\n",
      "                         f1     auc\n",
      "Logistic Regression  0.7843  0.9375\n",
      "Decision Tree        0.7143  0.7321\n",
      "Random Forest        0.7451  0.9213\n",
      "SVM                  0.8077  0.9509\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Baseline models (for comparison)\n",
    "print(\"Training baseline models...\")\n",
    "\n",
    "baseline_models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'SVM': SVC(random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "baseline_results = {}\n",
    "for name, model in baseline_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    baseline_results[name] = {\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "\n",
    "print(\"Baseline results (F1, AUC):\")\n",
    "print(pd.DataFrame(baseline_results).T.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "480937b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters...\n",
      "\n",
      "Logistic Regression - RandomizedSearchCV...\n",
      "Best params (Randomized): {'C': np.float64(0.20684494295802447), 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Logistic Regression - GridSearchCV around best...\n",
      "Best params (Grid): {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "Decision Tree - RandomizedSearchCV...\n",
      "Best params (Randomized): {'max_depth': 12, 'min_samples_leaf': 8, 'min_samples_split': 8}\n",
      "Decision Tree - GridSearchCV around best...\n",
      "Best params (Grid): {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 15}\n",
      "\n",
      "Random Forest - RandomizedSearchCV...\n",
      "Best params (Randomized): {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 84}\n",
      "Random Forest - GridSearchCV around best...\n",
      "Best params (Grid): {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "SVM - RandomizedSearchCV...\n",
      "Best params (Randomized): {'C': np.float64(1.6601864044243653), 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVM - GridSearchCV around best...\n",
      "Best params (Grid): {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "Hyperparameter tuning complete!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Hyperparameter Tuning (RandomizedSearchCV + GridSearchCV)\n",
    "print(\"Tuning hyperparameters...\")\n",
    "\n",
    "# Define parameter grids\n",
    "param_distributions = {\n",
    "    'Logistic Regression': {\n",
    "        'C': uniform(0.001, 10.0),\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': randint(2, 20),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 10)\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': randint(2, 20),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 10)\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': uniform(0.1, 10.0),\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    }\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['lbfgs'],\n",
    "        'penalty': ['l2']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [3, 5, 7, 10, None],\n",
    "        'min_samples_split': [2, 5, 10, 15],\n",
    "        'min_samples_leaf': [1, 2, 4, 6]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 150, 200, 300],\n",
    "        'max_depth': [None, 5, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Mapping from name to estimator\n",
    "estimators = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "# Run tuning\n",
    "best_models = {}\n",
    "for name, estimator in estimators.items():\n",
    "    print(f\"\\n{name} - RandomizedSearchCV...\")\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=param_distributions[name],\n",
    "        n_iter=25,\n",
    "        scoring='f1',\n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rs.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best params (Randomized): {rs.best_params_}\")\n",
    "\n",
    "    print(f\"{name} - GridSearchCV around best...\")\n",
    "    # Build a small grid around the best params when applicable\n",
    "    grid = param_grids[name]\n",
    "    gs = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=grid,\n",
    "        scoring='f1',\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(f\"Best params (Grid): {gs.best_params_}\")\n",
    "\n",
    "    # Select the best of the two by CV score\n",
    "    best_cv = max(rs.best_score_, gs.best_score_)\n",
    "    best_est = rs.best_estimator_ if rs.best_score_ >= gs.best_score_ else gs.best_estimator_\n",
    "    best_models[name] = best_est\n",
    "\n",
    "print(\"\\nHyperparameter tuning complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beaae38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing optimized models with baseline...\n",
      "                 Model  Baseline F1  Optimized F1  Baseline AUC  Optimized AUC\n",
      "0  Logistic Regression       0.7843        0.8077        0.9375         0.9397\n",
      "1        Decision Tree       0.7143        0.7200        0.7321         0.8599\n",
      "2        Random Forest       0.7451        0.8077        0.9213         0.9342\n",
      "3                  SVM       0.8077        0.7843        0.9509         0.9420\n",
      "\n",
      "Best performing model after tuning: Logistic Regression\n",
      "Optimized F1: 0.8077\n",
      "Optimized AUC: 0.9397\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Compare optimized models with baseline\n",
    "print(\"Comparing optimized models with baseline...\")\n",
    "\n",
    "comparison = []\n",
    "for name in baseline_models.keys():\n",
    "    # Baseline\n",
    "    base_f1 = baseline_results[name]['f1']\n",
    "    base_auc = baseline_results[name]['auc']\n",
    "    \n",
    "    # Optimized\n",
    "    model_opt = best_models[name]\n",
    "    y_pred_opt = model_opt.predict(X_test)\n",
    "    y_proba_opt = model_opt.predict_proba(X_test)[:, 1]\n",
    "    opt_f1 = f1_score(y_test, y_pred_opt)\n",
    "    opt_auc = roc_auc_score(y_test, y_proba_opt)\n",
    "    \n",
    "    comparison.append({\n",
    "        'Model': name,\n",
    "        'Baseline F1': base_f1,\n",
    "        'Optimized F1': opt_f1,\n",
    "        'Baseline AUC': base_auc,\n",
    "        'Optimized AUC': opt_auc\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Identify best model by F1 (then AUC as tie-breaker)\n",
    "best_row = comparison_df.sort_values(['Optimized F1', 'Optimized AUC'], ascending=False).iloc[0]\n",
    "best_model_name = best_row['Model']\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest performing model after tuning: {best_model_name}\")\n",
    "print(f\"Optimized F1: {best_row['Optimized F1']:.4f}\")\n",
    "print(f\"Optimized AUC: {best_row['Optimized AUC']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585cdc9",
   "metadata": {},
   "source": [
    "## Deliverables Completed\n",
    "\n",
    "### ✅ Step 1: Use GridSearchCV & RandomizedSearchCV to optimize model hyperparameters\n",
    "- Tuned hyperparameters for Logistic Regression, Decision Tree, Random Forest, and SVM\n",
    "- Used RandomizedSearchCV for broad exploration\n",
    "- Used GridSearchCV for fine-tuning near the best parameters\n",
    "\n",
    "### ✅ Step 2: Compare optimized models with baseline performance\n",
    "- Computed baseline (F1, AUC) for all models\n",
    "- Compared with optimized model performance on test set\n",
    "- Identified best performing model based on F1 (AUC tie-breaker)\n",
    "\n",
    "### ✅ Deliverable: Best performing model with optimized hyperparameters\n",
    "- Best model printed with optimized F1 and AUC\n",
    "- Ready for downstream evaluation, saving, and deployment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
